{
 "cells": [],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "### Machine Learning\n",
     "\n",
     "\n",
     "\n",
     "import numpy as np\n",
     "import pandas as pd\n",
     "import pickle as pkl\n",
     "import optuna\n",
     "from IPython.display import clear_output\n",
     "\n",
     "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
     "from sklearn.model_selection import train_test_split, cross_val_score\n",
     "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
     "from sklearn.metrics import r2_score, mean_squared_error\n",
     "from yellowbrick.model_selection import LearningCurve\n",
     "\n",
     "pd.set_option('display.max_columns', None)\n",
     "pd.set_option('display.max_rows', None)\n",
     "\n",
     "\n",
     "\n",
     "ml = pd.read_csv('../estimations/mlready.csv')\n",
     "ml = ml.fillna(0)\n",
     "\n",
     "\n",
     "\n",
     "ml = ml[(ml.SEASON > '1983-84') & (ml.SEASON != '2021-22')]\n",
     "\n",
     "\n",
     "\n",
     "ml[(ml.SEASON == '2021-22')]\n",
     "\n",
     "\n",
     "\n",
     "df = ml.drop(['GB', 'CONF','DIV','HOME','ROAD','OT','TEAM_ID','TEAM','SEASON'], axis=1)\n",
     "df['GAMEPLAYED'] = df['W'] + df['L']\n",
     "df['FG_PERC'] = df['FGM'] / df['FGA']\n",
     "df['FG3_PERC'] = df['FG3M'] / df['FG3A']\n",
     "df['FT_PERC'] = df['FTM'] / df['FTA']\n",
     "df['OREB_PERC'] = df['OREB'] / df['REB']\n",
     "df['DREB_PERC'] = df['DREB'] / df['REB']\n",
     "df['AST_PG'] = df['AST'] / df['GAMEPLAYED'] \n",
     "df['STL_PG'] = df['STL'] / df['GAMEPLAYED'] \n",
     "df['BLK_PG'] = df['BLK'] / df['GAMEPLAYED'] \n",
     "df['TOV_PG'] = df['TOV'] / df['GAMEPLAYED']\n",
     "df['PF_PG'] = df['PF'] / df['GAMEPLAYED']\n",
     "df['PTS_PG'] = df['PTS'] / df['GAMEPLAYED'] \n",
     "df.drop(['W','L','FGM','FGA','FG3M','FG3A','FTM','FTA','OREB','DREB','REB'], axis=1, inplace=True)\n",
     "df = df.fillna(0)\n",
     "df = df[['FG_PERC','FG3_PERC','FT_PERC','OREB_PERC','DREB_PERC','AST_PG','STL_PG','BLK_PG','TOV_PG','PF_PG','PTS_PG','PER','ELO','SCORE']]\n",
     "df.reset_index(drop=True,inplace=True)\n",
     "df.head(1)\n",
     "\n",
     "\n",
     "\n",
     "X = df.drop(['SCORE'], axis=1)\n",
     "y = df['SCORE']\n",
     "\n",
     "\n",
     "\n",
     "rf = RandomForestRegressor(random_state=42)\n",
     "rf_results = pd.DataFrame(np.sqrt(-cross_val_score(rf, X, y, cv=5, scoring='neg_mean_squared_error')))\n",
     "rf_results.mean()\n",
     "\n",
     "\n",
     "\n",
     "rf = RandomForestRegressor(random_state=42)\n",
     "rf.fit(X, y)\n",
     "imp = rf.feature_importances_\n",
     "pd.DataFrame({\"feature\": X.columns, \"importances\": imp}).sort_values(\n",
     "    \"importances\", ascending=False).head()\n",
     "\n",
     "\n",
     "\n",
     "def objective(trial):\n",
     "    \n",
     "    criterion = trial.suggest_categorical(\n",
     "        \"criterion\", [\"squared_error\", \"absolute_error\", \"poisson\"])\n",
     "    bootstrap = trial.suggest_categorical(\"bootstrap\", [\"True\", \"False\"])\n",
     "    max_depth = trial.suggest_int(\"max_depth\", 1, 30)\n",
     "    max_features = trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", \"log2\"])\n",
     "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 30)\n",
     "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 30)\n",
     "    min_weight_fraction_leaf = trial.suggest_float(\n",
     "        \"min_weight_fraction_leaf\", 1e-4, 1e-1)\n",
     "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\", 1e-4, 1e-1)\n",
     "    warm_start = trial.suggest_categorical(\"warm_start\", [\"True\", \"False\"])\n",
     "    ccp_alpha = trial.suggest_float(\"ccp_alpha\", 1e-4, 1e-1)\n",
     "    max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\", 2, 30)\n",
     "    n_estimators = trial.suggest_int(\"n_estimators\", 30, 170)\n",
     "\n",
     "    regr = RandomForestRegressor(\n",
     "        criterion=criterion,\n",
     "        bootstrap=bootstrap,\n",
     "        max_depth=max_depth,\n",
     "        max_features=max_features,\n",
     "        min_samples_split=min_samples_split,\n",
     "        min_samples_leaf=min_samples_leaf,\n",
     "        min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
     "        min_impurity_decrease=min_impurity_decrease,\n",
     "        warm_start=warm_start,\n",
     "        ccp_alpha=ccp_alpha,\n",
     "        max_leaf_nodes=max_leaf_nodes,\n",
     "        n_estimators=n_estimators,\n",
     "        n_jobs=-1,\n",
     "        random_state=42)\n",
     "    \n",
     "    score = np.sqrt(-cross_val_score(regr, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
     "    clear_output()\n",
     "    return score.mean()\n",
     "\n",
     "\n",
     "study = optuna.create_study(direction=\"minimize\")\n",
     "study.optimize(objective, n_trials=1000)\n",
     "\n",
     "\n",
     "\n",
     "study.best_params\n",
     "\n",
     "{'criterion': 'squared_error',\n",
     " 'bootstrap': 'False',\n",
     " 'max_depth': 21,\n",
     " 'max_features': 'auto',\n",
     " 'min_samples_split': 25,\n",
     " 'min_samples_leaf': 15,\n",
     " 'min_weight_fraction_leaf': 0.05371066000438781,\n",
     " 'min_impurity_decrease': 0.004444664005096809,\n",
     " 'warm_start': 'True',\n",
     " 'ccp_alpha': 0.0035994644016967767,\n",
     " 'max_leaf_nodes': 27,\n",
     " 'n_estimators': 118}\n",
     "\n",
     "\n",
     "\n",
     "rf = RandomForestRegressor(**study.best_params,random_state=42)\n",
     "rf.fit(X, y)\n",
     "rf_results = pd.DataFrame(np.sqrt(-cross_val_score(rf, X, y, cv=5, scoring='neg_mean_squared_error')))\n",
     "rf_results.mean()\n",
     "\n",
     " md\n",
     "\n",
     "Try to guess last season\n",
     "\n",
     "\n",
     "\n",
     "ml = pd.read_csv('../estimations/mlready.csv')\n",
     "ml = ml.fillna(0)\n",
     "ml = ml[(ml.SEASON == '2021-22')]\n",
     "idx = ml.TEAM\n",
     "df = ml.drop(['GB', 'CONF','DIV','HOME','ROAD','OT','TEAM_ID','TEAM','SEASON'], axis=1)\n",
     "df['GAMEPLAYED'] = df['W'] + df['L']\n",
     "df['FG_PERC'] = df['FGM'] / df['FGA']\n",
     "df['FG3_PERC'] = df['FG3M'] / df['FG3A']\n",
     "df['FT_PERC'] = df['FTM'] / df['FTA']\n",
     "df['OREB_PERC'] = df['OREB'] / df['REB']\n",
     "df['DREB_PERC'] = df['DREB'] / df['REB']\n",
     "df['AST_PG'] = df['AST'] / df['GAMEPLAYED'] \n",
     "df['STL_PG'] = df['STL'] / df['GAMEPLAYED'] \n",
     "df['BLK_PG'] = df['BLK'] / df['GAMEPLAYED'] \n",
     "df['TOV_PG'] = df['TOV'] / df['GAMEPLAYED']\n",
     "df['PF_PG'] = df['PF'] / df['GAMEPLAYED']\n",
     "df['PTS_PG'] = df['PTS'] / df['GAMEPLAYED'] \n",
     "df.drop(['W','L','FGM','FGA','FG3M','FG3A','FTM','FTA','OREB','DREB','REB'], axis=1, inplace=True)\n",
     "df = df.fillna(0)\n",
     "df = df[['FG_PERC','FG3_PERC','FT_PERC','OREB_PERC','DREB_PERC','AST_PG','STL_PG','BLK_PG','TOV_PG','PF_PG','PTS_PG','PER','ELO']]\n",
     "df.reset_index(drop=True,inplace=True)\n",
     "df.head(1)\n",
     "\n",
     "\n",
     "\n",
     "df['SCORE'] = rf.predict(df)\n",
     "\n",
     "\n",
     "\n",
     "df = df.set_index(idx).reset_index()\n",
     "\n",
     "\n",
     "\n",
     "ss = MinMaxScaler(feature_range=(0,100))\n",
     "df['SCORE'] = ss.fit_transform(df[['SCORE']])\n",
     "df[['TEAM','SCORE']].sort_values(by='SCORE', ascending=False).head(12)\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}