{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3028472c-ce76-4f38-965d-f944cc0c4c2c",
   "metadata": {},
   "source": [
    "# PER Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d880b7-2934-40fd-b774-d68807057034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from scipy import spatial\n",
    "from scipy.stats import weightedtau\n",
    "\n",
    "np.warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a0a982-8635-4b61-a3b1-26ce4d7ed6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players = pd.read_csv(\"data/all_players.csv\")\n",
    "all_teams = pd.read_csv(\"data/all_teams.csv\")\n",
    "merged = pd.read_csv(\"data/merged.csv\")\n",
    "with open(\"data/matches.pkl\", \"rb\") as file:\n",
    "    matches = pkl.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad2003-1057-4d4d-8a46-ccc8071af5f4",
   "metadata": {},
   "source": [
    "#### Metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69bc2a40-6220-407c-ab22-2d1d6cd66b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(year):\n",
    "\n",
    "    season = str(year - 1) + \"-\" + str(year)[-2:]\n",
    "\n",
    "    def compare_similarity(num, season):\n",
    "        real = pd.read_csv(f\"real/realper{season}.csv\").iloc[:num, :].PER.to_list()\n",
    "        est = pd.read_csv(f\"estimations/{season}.csv\").iloc[:num, :].PER.to_list()\n",
    "        result = 1 - spatial.distance.cosine(real, est)\n",
    "        tau, pvalue = weightedtau(real, est)\n",
    "        return np.round(result, 5), np.round(tau, 5)\n",
    "\n",
    "    metrics = pd.DataFrame(columns=[\"Cosine\", \"Tau\"])\n",
    "    for i in [10, 25, 50, 100, 200]:\n",
    "        result, tau = compare_similarity(i, season)\n",
    "        temp_df = pd.DataFrame(\n",
    "            {\"Cosine\": str(result), \"Tau\": str(tau)}, index=[f\"First {i}\"]\n",
    "        )\n",
    "        metrics = metrics.append([temp_df])\n",
    "\n",
    "    return metrics.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57ef935e-1cca-43fe-8761-4c841e75484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99981  0.99986   0.9999   0.99991   0.99992\n",
      "Tau         1.0      1.0      1.0   0.99956   0.99964\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine   0.9997   0.9997   0.9998   0.99981   0.99985\n",
      "Tau         1.0      1.0  0.99954   0.99963   0.99969\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99983   0.9999  0.99989   0.99992   0.99993\n",
      "Tau         1.0      1.0  0.99989   0.99977   0.99971\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99984  0.99979  0.99978   0.99985   0.99988\n",
      "Tau         1.0  0.99856   0.9988   0.99923   0.99953\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99885  0.99935  0.99951   0.99968   0.99978\n",
      "Tau         1.0      1.0  0.99964   0.99944   0.99963\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99981  0.99989  0.99993   0.99995   0.99994\n",
      "Tau     0.99143  0.99754  0.99858   0.99919   0.99948\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99992  0.99994  0.99994   0.99994   0.99995\n",
      "Tau         1.0      1.0  0.99978   0.99955   0.99962\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99974  0.99985  0.99988   0.99983   0.99988\n",
      "Tau         1.0  0.99896   0.9993   0.99951   0.99961\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine   0.9998  0.99986  0.99991   0.99993   0.99991\n",
      "Tau         1.0      1.0   0.9997   0.99948   0.99965\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99954  0.99966  0.99967   0.99973    0.9998\n",
      "Tau         1.0      1.0  0.99966   0.99964   0.99967\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99965  0.99956   0.9996    0.9997   0.99976\n",
      "Tau         1.0      1.0  0.99985   0.99974   0.99969\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99868  0.99927  0.99949   0.99962   0.99972\n",
      "Tau     0.99143  0.99709  0.99841   0.99913   0.99941\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99974  0.99979  0.99984   0.99988    0.9999\n",
      "Tau         1.0  0.99934  0.99948    0.9996   0.99967\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99984  0.99983  0.99984   0.99988   0.99991\n",
      "Tau         1.0      1.0   0.9998   0.99965   0.99968\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99922  0.99953  0.99964   0.99977   0.99979\n",
      "Tau     0.98427  0.99498  0.99708   0.99854   0.99919\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99589   0.9975  0.99845   0.99902    0.9992\n",
      "Tau         1.0  0.99944   0.9995   0.99958    0.9997\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99939  0.99964  0.99977   0.99984   0.99987\n",
      "Tau         1.0  0.99951  0.99958   0.99958   0.99967\n",
      "-----------------------------------------------------\n",
      "       First 10 First 25 First 50 First 100 First 200\n",
      "Cosine  0.99969  0.99982  0.99979   0.98976   0.97508\n",
      "Tau     0.99143  0.99754  0.99848   0.65084   0.47547\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(2005, 2023):\n",
    "    print(metrics(i))\n",
    "    print(53 * \"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5e7d9-987a-44be-9607-95ed6566f10c",
   "metadata": {},
   "source": [
    "## 2021-22 Season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775721ec-a254-4298-8627-dc910cad3f01",
   "metadata": {},
   "source": [
    "#### Live PER Ratings on  http://insider.espn.com/nba/hollinger/statistics for 2021-22 Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6ae53-db3a-4fdc-a626-00cda632a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First page\n",
    "live_ratings = pd.read_html(\"http://insider.espn.com/nba/hollinger/statistics\")[0]\n",
    "live_ratings = live_ratings.iloc[2:, 1:].reset_index(drop=True)\n",
    "\n",
    "# Other pages\n",
    "for i in range(2, 9):\n",
    "    temp_df = pd.read_html(\n",
    "        \"http://insider.espn.com/nba/hollinger/statistics/_/page/{page_num}\"\n",
    "    )[0]\n",
    "    temp_df = temp_df.iloc[2:, 1:].reset_index(drop=True)\n",
    "    live_ratings = pd.concat([live_ratings, temp_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Fix the format\n",
    "live_ratings.columns = [\n",
    "    \"PLAYER\",\n",
    "    \"GP\",\n",
    "    \"MPG\",\n",
    "    \"TS%\",\n",
    "    \"AST\",\n",
    "    \"TO\",\n",
    "    \"USG\",\n",
    "    \"ORR\",\n",
    "    \"DRR\",\n",
    "    \"REBR\",\n",
    "    \"PER\",\n",
    "    \"VA\",\n",
    "    \"EWA\",\n",
    "]\n",
    "live_ratings.PLAYER = live_ratings.PLAYER.apply(\n",
    "    lambda x: np.nan if x == \"PLAYER\" else x\n",
    ")\n",
    "live_ratings.dropna(inplace=True)\n",
    "live_ratings[\"abbrev\"] = live_ratings.PLAYER.apply(lambda x: x.split(\",\")[1].strip())\n",
    "live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "    lambda x: \"UTA\" if x == \"UTAH\" else x\n",
    ")\n",
    "live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "    lambda x: \"GSW\" if x == \"GS\" else x\n",
    ")\n",
    "live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "    lambda x: \"NOP\" if x == \"NO\" else x\n",
    ")\n",
    "live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "    lambda x: \"WAS\" if x == \"WSH\" else x\n",
    ")\n",
    "live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "    lambda x: \"SAS\" if x == \"SA\" else x\n",
    ")\n",
    "live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "    lambda x: \"NYK\" if x == \"NY\" else x\n",
    ")\n",
    "live_ratings[\"name\"] = live_ratings.PLAYER.apply(lambda x: x.split(\",\")[0])\n",
    "\n",
    "# Merge\n",
    "live_ratings = live_ratings.merge(\n",
    "    all_teams[[\"full_name\", \"abbreviation\"]],\n",
    "    left_on=\"abbrev\",\n",
    "    right_on=\"abbreviation\",\n",
    "    how=\"left\",\n",
    ")\n",
    "live_ratings.rename(columns={\"name\": \"FULLNAME\", \"full_name\": \"TEAM\"}, inplace=True)\n",
    "\n",
    "# Dump\n",
    "live_ratings[[\"FULLNAME\", \"TEAM\", \"PER\"]].to_csv(\n",
    "    f\"real/realper2021-22.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27460983-6316-4c5e-9d00-c8e83dcc5639",
   "metadata": {},
   "source": [
    "#### Standings from https://www.espn.com/nba/standings/_/group/league for 2021-22 Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbaa34-be89-47d2-ae9c-487fb77ca2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_name(row):\n",
    "    for i, val in enumerate(row):\n",
    "        if row == \"LACLA Clippers\":\n",
    "            return \"Los Angeles \" + row.split()[1]\n",
    "        if val.islower():\n",
    "            return row[i - 1 :]\n",
    "\n",
    "\n",
    "# Estimations\n",
    "final = pd.read_csv(\"estimations/2021-22.csv\")\n",
    "agg_final = (\n",
    "    final.groupby(\"TEAM\")\n",
    "    .PER.sum()\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"PER\", ascending=False)\n",
    ")\n",
    "\n",
    "# Real Standings\n",
    "standings_teams = pd.read_html(\"https://www.espn.com/nba/standings/_/group/league\")[0]\n",
    "error = standings_teams.columns[0]\n",
    "lst = standings_teams[error].to_list()\n",
    "lst.insert(0, error)\n",
    "standings_teams = pd.DataFrame({\"Team\": lst})\n",
    "standings_stats = pd.read_html(\"https://www.espn.com/nba/standings/_/group/league\")[1]\n",
    "\n",
    "# Merge\n",
    "standings = pd.concat([standings_teams, standings_stats], axis=1, ignore_index=True)\n",
    "standings.columns = [\n",
    "    \"Team\",\n",
    "    \"W\",\n",
    "    \"L\",\n",
    "    \"PCT\",\n",
    "    \"GB\",\n",
    "    \"HOME\",\n",
    "    \"AWAY\",\n",
    "    \"DIV\",\n",
    "    \"CONF\",\n",
    "    \"PPG\",\n",
    "    \"OPP PPG\",\n",
    "    \"DIFF\",\n",
    "    \"STRK\",\n",
    "    \"L10\",\n",
    "]\n",
    "standings.Team = standings.Team.apply(cut_name)\n",
    "real_standings = standings.merge(agg_final, left_on=\"Team\", right_on=\"TEAM\", how=\"left\")\n",
    "real_standings.drop(\"TEAM\", axis=1, inplace=True)\n",
    "\n",
    "# Return\n",
    "real_standings[[\"Team\", \"PER\"]].to_csv(\"standings/standings2021-22.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372115c8-7439-4f1d-b308-abf53e85726d",
   "metadata": {},
   "source": [
    "## Other Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f9b70-5c60-4695-8715-79f490ed3906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_live_ratings(year):\n",
    "\n",
    "    # First page\n",
    "    live_ratings = pd.read_html(\n",
    "        f\"http://insider.espn.com/nba/hollinger/statistics/_/year/{year}\"\n",
    "    )[0]\n",
    "    live_ratings = live_ratings.iloc[2:, 1:].reset_index(drop=True)\n",
    "\n",
    "    # Other pages\n",
    "    for i in range(2, 9):\n",
    "        temp_df = pd.read_html(\n",
    "            f\"http://insider.espn.com/nba/hollinger/statistics/_/page/{i}/year/{year}\"\n",
    "        )[0]\n",
    "        temp_df = temp_df.iloc[2:, 1:].reset_index(drop=True)\n",
    "        live_ratings = pd.concat([live_ratings, temp_df], axis=0, ignore_index=True)\n",
    "\n",
    "    # Fix the format\n",
    "    live_ratings.columns = [\n",
    "        \"PLAYER\",\n",
    "        \"GP\",\n",
    "        \"MPG\",\n",
    "        \"TS%\",\n",
    "        \"AST\",\n",
    "        \"TO\",\n",
    "        \"USG\",\n",
    "        \"ORR\",\n",
    "        \"DRR\",\n",
    "        \"REBR\",\n",
    "        \"PER\",\n",
    "        \"VA\",\n",
    "        \"EWA\",\n",
    "    ]\n",
    "    live_ratings.PLAYER = live_ratings.PLAYER.apply(\n",
    "        lambda x: np.nan if x == \"PLAYER\" else x\n",
    "    )\n",
    "    live_ratings.dropna(inplace=True)\n",
    "    live_ratings[\"abbrev\"] = live_ratings.PLAYER.apply(\n",
    "        lambda x: x.split(\",\")[1].strip()\n",
    "    )\n",
    "    live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "        lambda x: \"UTA\" if x == \"UTAH\" else x\n",
    "    )\n",
    "    live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "        lambda x: \"GSW\" if x == \"GS\" else x\n",
    "    )\n",
    "    live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "        lambda x: \"NOP\" if x == \"NO\" else x\n",
    "    )\n",
    "    live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "        lambda x: \"WAS\" if x == \"WSH\" else x\n",
    "    )\n",
    "    live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "        lambda x: \"SAS\" if x == \"SA\" else x\n",
    "    )\n",
    "    live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "        lambda x: \"NYK\" if x == \"NY\" else x\n",
    "    )\n",
    "    live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "        lambda x: \"BKN\" if x == \"HOU/BKN\" else x\n",
    "    )\n",
    "    live_ratings[\"abbrev\"] = live_ratings[\"abbrev\"].apply(\n",
    "        lambda x: \"CHI\" if x == \"ORL/CHI\" else x\n",
    "    )\n",
    "    live_ratings[\"name\"] = live_ratings.PLAYER.apply(lambda x: x.split(\",\")[0])\n",
    "\n",
    "    # Merge\n",
    "    live_ratings = live_ratings.merge(\n",
    "        all_teams[[\"full_name\", \"abbreviation\"]],\n",
    "        left_on=\"abbrev\",\n",
    "        right_on=\"abbreviation\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    live_ratings.rename(columns={\"name\": \"FULLNAME\", \"full_name\": \"TEAM\"}, inplace=True)\n",
    "    season = str(year - 1) + \"-\" + str(year)[-2:]\n",
    "\n",
    "    # Dump\n",
    "    live_ratings[[\"FULLNAME\", \"TEAM\", \"PER\"]].to_csv(\n",
    "        f\"real/realper{season}.csv\", index=False\n",
    "    )\n",
    "\n",
    "\n",
    "# Get all available years\n",
    "for i in range(2005, 2022):\n",
    "    get_live_ratings(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5e127-d2d5-4a4c-9bc0-dbad365abf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_standings(year):\n",
    "    season = str(year - 1) + \"-\" + str(year)[-2:]\n",
    "\n",
    "    def cut_name(row):\n",
    "        row = row[3:]\n",
    "        for i, val in enumerate(row):\n",
    "            if row == \"LACLA Clippers\":\n",
    "                return \"Los Angeles\" + row.split()[1]\n",
    "            if val.islower():\n",
    "                return row[i - 1 :]\n",
    "\n",
    "    # Estimations\n",
    "    final = pd.read_csv(f\"estimations/{season}.csv\")\n",
    "    agg_final = (\n",
    "        final.groupby(\"TEAM\")\n",
    "        .PER.sum()\n",
    "        .to_frame()\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"PER\", ascending=False)\n",
    "    )\n",
    "\n",
    "    # Real Standings\n",
    "    standings_teams = pd.read_html(\n",
    "        f\"https://www.espn.com/nba/standings/_/season/{year}/group/league\"\n",
    "    )[0]\n",
    "    error = standings_teams.columns[0]\n",
    "    lst = standings_teams[error].to_list()\n",
    "    lst.insert(0, error)\n",
    "    standings_teams = pd.DataFrame({\"Team\": lst})\n",
    "    standings_stats = pd.read_html(\n",
    "        f\"https://www.espn.com/nba/standings/_/season/{year}/group/league\"\n",
    "    )[1]\n",
    "\n",
    "    # Merge\n",
    "    standings = pd.concat([standings_teams, standings_stats], axis=1, ignore_index=True)\n",
    "    standings.columns = [\n",
    "        \"Team\",\n",
    "        \"W\",\n",
    "        \"L\",\n",
    "        \"PCT\",\n",
    "        \"GB\",\n",
    "        \"HOME\",\n",
    "        \"AWAY\",\n",
    "        \"DIV\",\n",
    "        \"CONF\",\n",
    "        \"PPG\",\n",
    "        \"OPP PPG\",\n",
    "        \"DIFF\",\n",
    "        \"STRK\",\n",
    "        \"L10\",\n",
    "    ]\n",
    "    standings.Team = standings.Team.apply(cut_name)\n",
    "    real_standings = standings.merge(\n",
    "        agg_final, left_on=\"Team\", right_on=\"TEAM\", how=\"left\"\n",
    "    )\n",
    "    real_standings.drop(\"TEAM\", axis=1, inplace=True)\n",
    "    season = str(year - 1) + \"-\" + str(year)[-2:]\n",
    "\n",
    "    # Return\n",
    "    real_standings[[\"Team\", \"PER\"]].to_csv(\n",
    "        f\"standings/standings{season}.csv\", index=False\n",
    "    )\n",
    "\n",
    "\n",
    "for i in range(2005, 2022):\n",
    "    get_real_standings(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
